{"cells": [{"cell_type": "markdown", "id": "253e1352", "metadata": {}, "source": ["# LSTM + ResNet Stress Classifier\n", "\n", "End-to-end exploration of a convolutional + recurrent model for stress-level prediction."]}, {"cell_type": "code", "execution_count": 1, "id": "41799f29", "metadata": {"execution": {"iopub.execute_input": "2025-12-10T21:54:11.146036Z", "iopub.status.busy": "2025-12-10T21:54:11.145833Z", "iopub.status.idle": "2025-12-10T21:54:13.477012Z", "shell.execute_reply": "2025-12-10T21:54:13.476248Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Device: cuda\n"]}], "source": ["\n", "import os\n", "import math\n", "from pathlib import Path\n", "from typing import List, Tuple\n", "\n", "import numpy as np\n", "import pandas as pd\n", "from tqdm.auto import tqdm\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.model_selection import GroupKFold\n", "from sklearn.metrics import classification_report, accuracy_score\n", "\n", "import torch\n", "from torch import nn\n", "import torch.nn.functional as F\n", "from torch.utils.data import Dataset, DataLoader\n", "\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "print(\"Device:\", device)"]}, {"cell_type": "code", "execution_count": 2, "id": "03f46d09", "metadata": {"execution": {"iopub.execute_input": "2025-12-10T21:54:13.480680Z", "iopub.status.busy": "2025-12-10T21:54:13.479972Z", "iopub.status.idle": "2025-12-10T21:54:13.483972Z", "shell.execute_reply": "2025-12-10T21:54:13.483224Z"}}, "outputs": [], "source": ["# Configuration\n", "DEFAULT_DATASET_ROOT = Path(\"./Datasets\")\n", "DATASET_ROOT = Path(os.getenv(\"DATASET_ROOT\", DEFAULT_DATASET_ROOT))\n", "STATES = [\"STRESS\", \"AEROBIC\", \"ANAEROBIC\"]\n", "TARGET_FS = 4.0\n", "WINDOW_SECONDS = 60\n", "WINDOW_STEP_SECONDS = 30\n", "MIN_LABEL_COVERAGE = 0.6\n", "SEED = 42\n", "MAX_SUBJECTS = None  # limit per state if desired\n", "APPLY_CHANNEL_NORMALIZATION = True\n", "APPLY_DIFF_CHANNELS = True\n", "APPLY_SMOTE = True\n", "\n", "# Cross-subject revalidation setup\n", "GROUP_SPLIT = True\n", "NUM_FOLDS = 5\n", "FOLD_INDEX = 0\n"]}, {"cell_type": "code", "execution_count": 3, "id": "e44a274b", "metadata": {"execution": {"iopub.execute_input": "2025-12-10T21:54:13.486581Z", "iopub.status.busy": "2025-12-10T21:54:13.486255Z", "iopub.status.idle": "2025-12-10T21:54:13.508081Z", "shell.execute_reply": "2025-12-10T21:54:13.506792Z"}}, "outputs": [], "source": ["\n", "# Helper functions for Empatica-format data\n", "STRESS_STAGE_ORDER_S = [\"Stroop\", \"TMCT\", \"Real Opinion\", \"Opposite Opinion\", \"Subtract\"]\n", "STRESS_STAGE_ORDER_F = [\"TMCT\", \"Real Opinion\", \"Opposite Opinion\", \"Subtract\"]\n", "STRESS_TAG_PAIRS_S = [(3, 4), (5, 6), (7, 8), (9, 10), (11, 12)]\n", "STRESS_TAG_PAIRS_F = [(2, 3), (4, 5), (6, 7), (8, 9)]\n", "STRESS_PHASES = {\"Stroop\", \"TMCT\", \"Real Opinion\", \"Opposite Opinion\", \"Subtract\"}\n", "STRESS_LEVEL_BOUNDS = {\"low\": 3.0, \"moderate\": 6.0}\n", "STRESS_LEVEL_PHASE_BOUNDS = {\n", "    \"Stroop\": {\"low\": 2.5, \"moderate\": 5.0},\n", "    \"Opposite Opinion\": {\"low\": 2.5, \"moderate\": 5.5},\n", "    \"Real Opinion\": {\"low\": 2.8, \"moderate\": 5.5},\n", "    \"TMCT\": {\"low\": 2.8, \"moderate\": 5.8},\n", "    \"Subtract\": {\"low\": 2.8, \"moderate\": 5.8},\n", "}\n", "STRESS_LEVEL_FILES = [\"Stress_Level_v1.csv\", \"Stress_Level_v2.csv\"]\n", "MIN_LABEL_COVERAGE = 0.6\n", "\n", "\n", "def load_stress_levels():\n", "    levels = {}\n", "    for fname in STRESS_LEVEL_FILES:\n", "        path = Path(fname)\n", "        if not path.exists():\n", "            continue\n", "        df = pd.read_csv(path, index_col=0)\n", "        df.columns = [str(c).strip() for c in df.columns]\n", "        for subject, row in df.iterrows():\n", "            subj = str(subject).strip()\n", "            levels[subj] = {\n", "                col: (float(row[col]) if not pd.isna(row[col]) else np.nan)\n", "                for col in df.columns\n", "            }\n", "    return levels\n", "\n", "\n", "STRESS_LEVELS = load_stress_levels()\n", "\n", "\n", "def base_subject_id(subject: str) -> str:\n", "    return subject.split(\"_\")[0]\n", "\n", "\n", "def read_signal(path: Path):\n", "    with open(path, \"r\") as f:\n", "        start_line = f.readline().strip()\n", "        if not start_line:\n", "            raise ValueError(f\"Missing start timestamp in {path}\")\n", "        start_ts = pd.to_datetime(start_line.split(\",\")[0])\n", "        fs_line = f.readline().strip()\n", "        if not fs_line:\n", "            raise ValueError(f\"Missing sample rate in {path}\")\n", "        fs = float(fs_line.split(\",\")[0])\n", "        data = np.genfromtxt(f, delimiter=\",\")\n", "    data = np.asarray(data, dtype=float)\n", "    if data.ndim == 0:\n", "        data = data.reshape(1, 1)\n", "    return fs, data.squeeze(), start_ts\n", "\n", "\n", "def read_tags(path: Path, start_ts: pd.Timestamp):\n", "    if not path.exists():\n", "        return []\n", "    df = pd.read_csv(path, header=None)\n", "    tags = []\n", "    for ts_str in df[0].astype(str):\n", "        ts = pd.to_datetime(ts_str)\n", "        tags.append((ts - start_ts).total_seconds())\n", "    return [(t, t) for t in tags]\n", "\n", "\n", "def stress_intervals_from_tags(tags, subject):\n", "    if not tags:\n", "        return []\n", "    times = [t for t, _ in tags]\n", "    if subject.startswith(\"S\"):\n", "        idx_pairs = STRESS_TAG_PAIRS_S\n", "        stage_order = STRESS_STAGE_ORDER_S\n", "    else:\n", "        idx_pairs = STRESS_TAG_PAIRS_F\n", "        stage_order = STRESS_STAGE_ORDER_F\n", "    base_id = base_subject_id(subject)\n", "    spans = []\n", "    for stage, (i, j) in zip(stage_order, idx_pairs):\n", "        if i < len(times) and j < len(times) and times[j] > times[i]:\n", "            level = STRESS_LEVELS.get(base_id, {}).get(stage)\n", "            spans.append({\"start\": times[i], \"end\": times[j], \"stage\": stage, \"stress_level\": level})\n", "    return spans\n", "\n", "\n", "def active_intervals_from_tags(tags):\n", "    if len(tags) < 2:\n", "        return []\n", "    spans = []\n", "    for (a, _), (b, _) in zip(tags[:-1], tags[1:]):\n", "        if b > a:\n", "            spans.append({\"start\": a, \"end\": b, \"stage\": \"active\", \"stress_level\": 0.0})\n", "    return spans\n", "\n", "\n", "def stress_bucket(level: float = None, phase: str = None) -> str:\n", "    if phase in {\"aerobic\", \"anaerobic\", \"rest\", \"active\"}:\n", "        return \"no_stress\"\n", "    if level is None or pd.isna(level) or level <= 0:\n", "        return \"no_stress\"\n", "    bounds = STRESS_LEVEL_PHASE_BOUNDS.get(phase, STRESS_LEVEL_BOUNDS)\n", "    if level <= bounds[\"low\"]:\n", "        return \"low_stress\"\n", "    if level <= bounds[\"moderate\"]:\n", "        return \"moderate_stress\"\n", "    return \"high_stress\"\n", "\n", "\n", "def resample_to_rate(signal: np.ndarray, src_fs: float, tgt_fs: float) -> np.ndarray:\n", "    if signal.ndim == 1:\n", "        signal = signal[:, None]\n", "    src_len = signal.shape[0]\n", "    duration = src_len / src_fs\n", "    tgt_len = int(duration * tgt_fs)\n", "    if tgt_len <= 0:\n", "        return np.zeros((0, signal.shape[1]))\n", "    src_t = np.linspace(0, duration, src_len, endpoint=False)\n", "    tgt_t = np.linspace(0, duration, tgt_len, endpoint=False)\n", "    resampled = np.vstack([\n", "        np.interp(tgt_t, src_t, signal[:, i])\n", "        for i in range(signal.shape[1])\n", "    ]).T\n", "    if resampled.shape[1] == 1:\n", "        return resampled[:, 0]\n", "    return resampled\n", "\n", "\n", "def window_intervals(duration: float, win_s: int, step_s: int):\n", "    windows = []\n", "    t = 0.0\n", "    while t + win_s <= duration:\n", "        windows.append((t, t + win_s))\n", "        t += step_s\n", "    return windows\n", "\n", "\n", "def assign_label(win, intervals):\n", "    start, end = win\n", "    length = end - start\n", "    best_label = None\n", "    best_cov = 0.0\n", "    best_span = None\n", "    for label, spans in intervals.items():\n", "        overlap = 0.0\n", "        span_choice = None\n", "        span_overlap = 0.0\n", "        for span in spans:\n", "            a = span[\"start\"] if isinstance(span, dict) else span[0]\n", "            b = span[\"end\"] if isinstance(span, dict) else span[1]\n", "            inter = max(0.0, min(end, b) - max(start, a))\n", "            if inter > 0:\n", "                overlap += inter\n", "                if inter > span_overlap:\n", "                    span_overlap = inter\n", "                    span_choice = span\n", "        coverage = overlap / length\n", "        if coverage > best_cov:\n", "            best_cov = coverage\n", "            best_label = label\n", "            best_span = span_choice\n", "    if best_cov >= MIN_LABEL_COVERAGE and best_label is not None:\n", "        return best_label, best_span\n", "    return None, None\n", "\n", "\n", "def make_label_intervals(state: str, subject: str, tags, duration: float):\n", "    rest_span = [{\"start\": 0.0, \"end\": duration, \"stage\": \"rest\", \"stress_level\": 0.0}]\n", "    if state == \"STRESS\":\n", "        stress_spans = stress_intervals_from_tags(tags, subject)\n", "        if not stress_spans:\n", "            return {\"rest\": rest_span}\n", "        return {\"stress\": stress_spans, \"rest\": rest_span}\n", "    active = active_intervals_from_tags(tags)\n", "    label = \"aerobic\" if state == \"AEROBIC\" else \"anaerobic\"\n", "    if not active:\n", "        return {label: rest_span, \"rest\": rest_span}\n", "    return {label: active, \"rest\": rest_span}\n", "\n", "\n", "def load_subject_state(state: str, subject: str):\n", "    folder = DATASET_ROOT / state / subject\n", "    if not folder.exists():\n", "        raise FileNotFoundError(folder)\n", "    fs_eda, eda_raw, start_ts = read_signal(folder / \"EDA.csv\")\n", "    temp_path = folder / \"TEMP.csv\"\n", "    if temp_path.exists():\n", "        fs_temp, temp_raw, _ = read_signal(temp_path)\n", "    else:\n", "        fs_temp, temp_raw = fs_eda, np.zeros_like(eda_raw)\n", "    fs_acc, acc_raw, _ = read_signal(folder / \"ACC.csv\")\n", "    acc_raw = np.atleast_2d(acc_raw)\n", "    acc_mag = np.linalg.norm(acc_raw, axis=1)\n", "    bvp_path = folder / \"BVP.csv\"\n", "    if bvp_path.exists():\n", "        fs_bvp, bvp_raw, _ = read_signal(bvp_path)\n", "    else:\n", "        fs_bvp, bvp_raw = None, None\n", "    tags = read_tags(folder / \"tags.csv\", start_ts)\n", "    sensors = {\n", "        \"EDA\": np.asarray(eda_raw, dtype=float),\n", "        \"TEMP\": np.asarray(temp_raw, dtype=float),\n", "        \"ACC_MAG\": acc_mag,\n", "    }\n", "    if bvp_raw is not None:\n", "        sensors[\"BVP\"] = np.asarray(bvp_raw, dtype=float)\n", "    fs_map = {\"EDA\": fs_eda, \"TEMP\": fs_temp, \"ACC_MAG\": fs_acc}\n", "    if fs_bvp:\n", "        fs_map[\"BVP\"] = fs_bvp\n", "    duration = len(sensors[\"EDA\"]) / fs_eda\n", "    return {\"sensors\": sensors, \"fs\": fs_map, \"tags\": tags, \"duration\": duration}\n"]}, {"cell_type": "code", "execution_count": 4, "id": "83737a60", "metadata": {"execution": {"iopub.execute_input": "2025-12-10T21:54:13.511599Z", "iopub.status.busy": "2025-12-10T21:54:13.511207Z", "iopub.status.idle": "2025-12-10T21:54:13.520710Z", "shell.execute_reply": "2025-12-10T21:54:13.520078Z"}}, "outputs": [], "source": ["EXPECTED_LEN = int(WINDOW_SECONDS * TARGET_FS)\n", "BASE_CHANNELS = [\"EDA\", \"TEMP\", \"ACC\", \"BVP\"]\n", "\n", "\n", "def _slice_or_pad(signal: np.ndarray, start: int, end: int) -> np.ndarray:\n", "    length = end - start\n", "    if signal is None or len(signal) == 0:\n", "        return np.zeros(length, dtype=np.float32)\n", "    if end > len(signal):\n", "        pad = end - len(signal)\n", "        segment = signal[start: len(signal)]\n", "        if pad > 0:\n", "            segment = np.concatenate([segment, np.zeros(pad, dtype=segment.dtype)])\n", "        return segment.astype(np.float32)\n", "    return signal[start:end].astype(np.float32)\n", "\n", "\n", "def extract_enhanced_channels(eda, temp, acc, bvp, fs=4.0):\n", "    \"\"\"\n", "    PHASE 1.2: Extract enhanced channel features.\n", "    Adds 8 new channels for stress-relevant patterns.\n", "    \"\"\"\n", "    from scipy.signal import hilbert\n", "    \n", "    channels = [eda, temp, acc, bvp]  # Original 4 channels\n", "    \n", "    # First-order derivatives (rate of change)\n", "    channels.extend([\n", "        np.diff(eda, prepend=eda[0]),\n", "        np.diff(temp, prepend=temp[0]),\n", "        np.diff(acc, prepend=acc[0]),\n", "        np.diff(bvp, prepend=bvp[0])\n", "    ])\n", "    \n", "    # EDA decomposition (tonic = slow baseline, phasic = SCR responses)\n", "    window_tonic = int(10 * fs)  # 10 second moving average\n", "    eda_tonic = np.convolve(eda, np.ones(window_tonic)/window_tonic, mode='same')\n", "    eda_phasic = eda - eda_tonic\n", "    channels.extend([eda_tonic, eda_phasic])\n", "    \n", "    # Second-order derivative (acceleration of EDA - captures SCR onset speed)\n", "    eda_diff = np.diff(eda, prepend=eda[0])\n", "    eda_accel = np.diff(eda_diff, prepend=eda_diff[0])\n", "    channels.append(eda_accel)\n", "    \n", "    # Moving averages for trend detection\n", "    window_short = int(5 * fs)   # 5-second trend\n", "    window_long = int(15 * fs)   # 15-second trend\n", "    eda_ma_short = np.convolve(eda, np.ones(window_short)/window_short, mode='same')\n", "    eda_ma_long = np.convolve(eda, np.ones(window_long)/window_long, mode='same')\n", "    channels.extend([eda_ma_short, eda_ma_long])\n", "    \n", "    # BVP envelope (HRV proxy via Hilbert transform)\n", "    bvp_envelope = np.abs(hilbert(bvp))\n", "    channels.append(bvp_envelope)\n", "    \n", "    # Cross-channel interaction (autonomic coordination)\n", "    eda_bvp_interaction = eda * bvp\n", "    channels.append(eda_bvp_interaction)\n", "    \n", "    # Smoothed ACC (remove high-frequency noise)\n", "    acc_smoothed = np.convolve(acc, np.ones(int(3*fs))/(3*fs), mode='same')\n", "    channels.append(acc_smoothed)\n", "    \n", "    return np.stack(channels, axis=0)  # 16 total channels\n", "\n", "\n", "def build_sequence_dataset(states: List[str] = STATES, max_subjects: int = 0) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n", "    sequences = []\n", "    labels = []\n", "    subjects = []\n", "    for state in states:\n", "        state_dir = DATASET_ROOT / state\n", "        if not state_dir.exists():\n", "            continue\n", "        subject_ids = sorted([p.name for p in state_dir.iterdir() if p.is_dir()])\n", "        if max_subjects and max_subjects > 0:\n", "            subject_ids = subject_ids[:max_subjects]\n", "        for subj in tqdm(subject_ids, desc=f\"{state}\"):\n", "            try:\n", "                info = load_subject_state(state, subj)\n", "            except Exception as exc:\n", "                print(f\"Skip {state}/{subj}: {exc}\")\n", "                continue\n", "            sensors = info[\"sensors\"]\n", "            fs_map = info[\"fs\"]\n", "            tags = info[\"tags\"]\n", "            duration = info[\"duration\"]\n", "\n", "            eda = resample_to_rate(sensors[\"EDA\"], fs_map[\"EDA\"], TARGET_FS)\n", "            temp = resample_to_rate(sensors.get(\"TEMP\", np.zeros_like(eda)), fs_map.get(\"TEMP\", TARGET_FS), TARGET_FS) if \"TEMP\" in sensors else np.zeros_like(eda)\n", "            acc = resample_to_rate(sensors[\"ACC_MAG\"], fs_map[\"ACC_MAG\"], TARGET_FS)\n", "            if \"BVP\" in sensors and \"BVP\" in fs_map:\n", "                bvp = resample_to_rate(sensors[\"BVP\"], fs_map[\"BVP\"], TARGET_FS)\n", "            else:\n", "                bvp = np.zeros_like(eda)\n", "\n", "            intervals = make_label_intervals(state, subj, tags, duration)\n", "            windows = window_intervals(duration, WINDOW_SECONDS, WINDOW_STEP_SECONDS)\n", "\n", "            for win in windows:\n", "                label_name, span_meta = assign_label(win, intervals)\n", "                if label_name is None or span_meta is None:\n", "                    continue\n", "                start_idx = int(round(win[0] * TARGET_FS))\n", "                end_idx = start_idx + EXPECTED_LEN\n", "                eda_win = _slice_or_pad(eda, start_idx, end_idx)\n", "                temp_win = _slice_or_pad(temp, start_idx, end_idx)\n", "                acc_win = _slice_or_pad(acc, start_idx, end_idx)\n", "                bvp_win = _slice_or_pad(bvp, start_idx, end_idx)\n", "\n", "                stress_stage = span_meta.get(\"stage\") if isinstance(span_meta, dict) else None\n", "                stress_level = span_meta.get(\"stress_level\") if isinstance(span_meta, dict) else None\n", "                if label_name == \"stress\":\n", "                    if stress_level is None or np.isnan(stress_level):\n", "                        continue\n", "                else:\n", "                    stress_level = 0.0\n", "                phase_label = stress_stage if stress_stage else label_name\n", "                stress_class = stress_bucket(stress_level, phase_label)\n", "\n", "                # PHASE 1.2: Extract enhanced channels (16 total)\n", "                tensor = extract_enhanced_channels(eda_win, temp_win, acc_win, bvp_win, TARGET_FS)\n", "                \n", "                sequences.append(tensor)\n", "                labels.append(stress_class)\n", "                subjects.append(base_subject_id(subj))\n", "    \n", "    sequences = np.stack(sequences).astype(np.float32)\n", "    labels = np.array(labels)\n", "    subjects = np.array(subjects)\n", "    return sequences, labels, subjects"]}, {"cell_type": "code", "execution_count": 5, "id": "a4fa9274", "metadata": {"execution": {"iopub.execute_input": "2025-12-10T21:54:13.522809Z", "iopub.status.busy": "2025-12-10T21:54:13.522295Z", "iopub.status.idle": "2025-12-10T21:54:31.503452Z", "shell.execute_reply": "2025-12-10T21:54:31.502680Z"}}, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "af4e356b48974913a1d746d3f9b3c3a0", "version_major": 2, "version_minor": 0}, "text/plain": ["STRESS:   0%|          | 0/37 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["Skip STRESS/f14_a: No columns to parse from file\n"]}, {"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "5092a273c5bd448e93d77dd1aba21215", "version_major": 2, "version_minor": 0}, "text/plain": ["AEROBIC:   0%|          | 0/31 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "e5f51226b8024880b3a279f107fb33ac", "version_major": 2, "version_minor": 0}, "text/plain": ["ANAEROBIC:   0%|          | 0/32 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["================================================================================\n", "DATASET STATISTICS\n", "================================================================================\n", "\n", "Raw sequences: (6788, 16, 240)\n", "Channels: 16\n", "Channel names: ['EDA', 'TEMP', 'ACC', 'BVP', 'EDA_diff', 'TEMP_diff', 'ACC_diff', 'BVP_diff', 'EDA_tonic', 'EDA_phasic', 'EDA_accel', 'EDA_ma_short', 'EDA_ma_long', 'BVP_envelope', 'EDA_BVP_interaction', 'ACC_smoothed']\n", "\n", "Label distribution:\n", "  high_stress         :   462 (  6.8%)\n", "  low_stress          :    91 (  1.3%)\n", "  moderate_stress     :   664 (  9.8%)\n", "  no_stress           :  5571 ( 82.1%)\n", "\n", "================================================================================\n", "APPLYING SUBJECT-SPECIFIC BASELINE NORMALIZATION\n", "================================================================================\n", "  S01     :  155 rest windows \u2192 baseline\n", "  S02     :  188 rest windows \u2192 baseline\n", "  S03     :  122 rest windows \u2192 baseline\n", "  S04     :  140 rest windows \u2192 baseline\n", "  S05     :  136 rest windows \u2192 baseline\n", "  S06     :  124 rest windows \u2192 baseline\n", "  S07     :  124 rest windows \u2192 baseline\n", "  S08     :  135 rest windows \u2192 baseline\n", "  S09     :  137 rest windows \u2192 baseline\n", "  S10     :  137 rest windows \u2192 baseline\n", "  S11     :  130 rest windows \u2192 baseline\n", "  S12     :   69 rest windows \u2192 baseline\n", "  S13     :  140 rest windows \u2192 baseline\n", "  S14     :  143 rest windows \u2192 baseline\n", "  S15     :  138 rest windows \u2192 baseline\n", "  S16     :  146 rest windows \u2192 baseline\n", "  S17     :  140 rest windows \u2192 baseline\n", "  S18     :  140 rest windows \u2192 baseline\n", "  f01     :  217 rest windows \u2192 baseline\n", "  f02     :  195 rest windows \u2192 baseline\n", "  f03     :  241 rest windows \u2192 baseline\n", "  f04     :  197 rest windows \u2192 baseline\n", "  f05     :  277 rest windows \u2192 baseline\n", "  f06     :  198 rest windows \u2192 baseline\n", "  f07     :  214 rest windows \u2192 baseline\n", "  f08     :  204 rest windows \u2192 baseline\n", "  f09     :  198 rest windows \u2192 baseline\n", "  f10     :  171 rest windows \u2192 baseline\n", "  f11     :  204 rest windows \u2192 baseline\n", "  f12     :  263 rest windows \u2192 baseline\n", "  f13     :  246 rest windows \u2192 baseline\n", "  f14     :   29 rest windows \u2192 baseline\n", "  f15     :   95 rest windows \u2192 baseline\n", "  f16     :   57 rest windows \u2192 baseline\n", "  f17     :   61 rest windows \u2192 baseline\n", "  f18     :   60 rest windows \u2192 baseline\n", "\n", "\u2713 Subject-specific normalization complete\n", "\n", "================================================================================\n", "FINAL DATASET: (6788, 16, 240)\n", "Subjects: 36\n", "================================================================================\n"]}], "source": ["sequences, labels, subjects = build_sequence_dataset(max_subjects=MAX_SUBJECTS if MAX_SUBJECTS else 0)\n", "\n", "# Define channel names for 16-channel input\n", "channel_names = [\n", "    'EDA', 'TEMP', 'ACC', 'BVP',                          # Original (4)\n", "    'EDA_diff', 'TEMP_diff', 'ACC_diff', 'BVP_diff',      # First derivatives (4)\n", "    'EDA_tonic', 'EDA_phasic',                             # EDA decomposition (2)\n", "    'EDA_accel',                                           # Second derivative (1)\n", "    'EDA_ma_short', 'EDA_ma_long',                         # Moving averages (2)\n", "    'BVP_envelope',                                        # BVP envelope (1)\n", "    'EDA_BVP_interaction',                                 # Cross-channel (1)\n", "    'ACC_smoothed'                                         # Smoothed ACC (1)\n", "]\n", "\n", "print(\"=\"*80)\n", "print(\"DATASET STATISTICS\")\n", "print(\"=\"*80)\n", "print(f\"\\nRaw sequences: {sequences.shape}\")\n", "print(f\"Channels: {len(channel_names)}\")\n", "print(f\"Channel names: {channel_names}\")\n", "print(f\"\\nLabel distribution:\")\n", "label_dist = pd.Series(labels).value_counts().sort_index()\n", "for label, count in label_dist.items():\n", "    pct = 100 * count / len(labels)\n", "    print(f\"  {label:20s}: {count:5d} ({pct:5.1f}%)\")\n", "\n", "# PHASE 1.1: Subject-Specific Baseline Normalization (HIGHEST IMPACT: +5-7% macro F1)\n", "if APPLY_CHANNEL_NORMALIZATION and sequences.size:\n", "    print(\"\\n\" + \"=\"*80)\n", "    print(\"APPLYING SUBJECT-SPECIFIC BASELINE NORMALIZATION\")\n", "    print(\"=\"*80)\n", "    normalized = sequences.copy()\n", "    \n", "    for subject in np.unique(subjects):\n", "        subject_mask = subjects == subject\n", "        rest_mask = subject_mask & (labels == 'no_stress')\n", "        \n", "        if rest_mask.sum() > 0:\n", "            baseline_mean = sequences[rest_mask].mean(axis=(0, 2), keepdims=True)\n", "            baseline_std = sequences[rest_mask].std(axis=(0, 2), keepdims=True) + 1e-6\n", "            print(f\"  {subject:8s}: {rest_mask.sum():4d} rest windows \u2192 baseline\")\n", "        else:\n", "            baseline_mean = sequences[subject_mask].mean(axis=(0, 2), keepdims=True)\n", "            baseline_std = sequences[subject_mask].std(axis=(0, 2), keepdims=True) + 1e-6\n", "            print(f\"  {subject:8s}: {subject_mask.sum():4d} total windows (NO REST DATA)\")\n", "        \n", "        normalized[subject_mask] = (sequences[subject_mask] - baseline_mean) / baseline_std\n", "    \n", "    sequences = normalized\n", "    print(\"\\n\u2713 Subject-specific normalization complete\")\n", "\n", "print(\"\\n\" + \"=\"*80)\n", "print(f\"FINAL DATASET: {sequences.shape}\")\n", "print(f\"Subjects: {len(np.unique(subjects))}\")\n", "print(\"=\"*80)"]}, {"cell_type": "code", "execution_count": 6, "id": "e9eb44aa", "metadata": {"execution": {"iopub.execute_input": "2025-12-10T21:54:31.506411Z", "iopub.status.busy": "2025-12-10T21:54:31.506021Z", "iopub.status.idle": "2025-12-10T21:54:31.510342Z", "shell.execute_reply": "2025-12-10T21:54:31.509235Z"}}, "outputs": [], "source": ["\n", "class SequenceDataset(Dataset):\n", "    def __init__(self, data: np.ndarray, labels: np.ndarray):\n", "        self.features = torch.from_numpy(data)\n", "        self.labels = torch.from_numpy(labels).long()\n", "\n", "    def __len__(self):\n", "        return len(self.features)\n", "\n", "    def __getitem__(self, idx):\n", "        return self.features[idx], self.labels[idx]\n"]}, {"cell_type": "code", "execution_count": 7, "id": "cb4a1b2d", "metadata": {"execution": {"iopub.execute_input": "2025-12-10T21:54:31.512696Z", "iopub.status.busy": "2025-12-10T21:54:31.512457Z", "iopub.status.idle": "2025-12-10T21:54:31.517570Z", "shell.execute_reply": "2025-12-10T21:54:31.516923Z"}}, "outputs": [], "source": ["class ResNetBlock(nn.Module):\n", "    def __init__(self, channels: int, kernel_size: int = 5, dilation: int = 1):\n", "        super().__init__()\n", "        padding = ((kernel_size - 1) // 2) * dilation\n", "        self.conv1 = nn.Conv1d(channels, channels, kernel_size, padding=padding, dilation=dilation)\n", "        self.bn1 = nn.BatchNorm1d(channels)\n", "        self.conv2 = nn.Conv1d(channels, channels, kernel_size, padding=padding, dilation=dilation)\n", "        self.bn2 = nn.BatchNorm1d(channels)\n", "        self.relu = nn.ReLU(inplace=True)\n", "\n", "    def forward(self, x):\n", "        identity = x\n", "        out = self.relu(self.bn1(self.conv1(x)))\n", "        out = self.bn2(self.conv2(out))\n", "        out += identity\n", "        return self.relu(out)\n", "\n", "\n", "class MultiScaleLSTMResNet(nn.Module):\n", "    \"\"\"Phase 2 architecture: multi-scale convolutions + BiLSTM + attention.\"\"\"\n", "\n", "    def __init__(self, input_channels: int, num_classes: int = 4, cnn_channels: int = 64):\n", "        super().__init__()\n", "        self.conv_short = nn.Sequential(\n", "            nn.Conv1d(input_channels, cnn_channels, kernel_size=3, padding=1),\n", "            nn.BatchNorm1d(cnn_channels),\n", "            nn.ReLU(),\n", "            ResNetBlock(cnn_channels, kernel_size=3, dilation=1),\n", "            ResNetBlock(cnn_channels, kernel_size=3, dilation=1),\n", "        )\n", "        self.conv_medium = nn.Sequential(\n", "            nn.Conv1d(input_channels, cnn_channels, kernel_size=7, padding=3),\n", "            nn.BatchNorm1d(cnn_channels),\n", "            nn.ReLU(),\n", "            ResNetBlock(cnn_channels, kernel_size=7, dilation=2),\n", "            ResNetBlock(cnn_channels, kernel_size=7, dilation=2),\n", "        )\n", "        self.conv_long = nn.Sequential(\n", "            nn.Conv1d(input_channels, cnn_channels, kernel_size=15, padding=7),\n", "            nn.BatchNorm1d(cnn_channels),\n", "            nn.ReLU(),\n", "            ResNetBlock(cnn_channels, kernel_size=15, dilation=4),\n", "            ResNetBlock(cnn_channels, kernel_size=15, dilation=4),\n", "        )\n", "\n", "        merged_channels = cnn_channels * 3\n", "        self.merge = nn.Sequential(\n", "            nn.Conv1d(merged_channels, 128, kernel_size=1),\n", "            nn.BatchNorm1d(128),\n", "            nn.ReLU(),\n", "        )\n", "\n", "        self.lstm = nn.LSTM(\n", "            input_size=128,\n", "            hidden_size=128,\n", "            num_layers=3,\n", "            dropout=0.3,\n", "            batch_first=True,\n", "            bidirectional=True,\n", "        )\n", "        self.attention = nn.MultiheadAttention(embed_dim=256, num_heads=8, dropout=0.2, batch_first=True)\n", "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n", "        self.classifier = nn.Sequential(\n", "            nn.Linear(256 + 128, 256),\n", "            nn.ReLU(),\n", "            nn.Dropout(0.3),\n", "            nn.Linear(256, 128),\n", "            nn.ReLU(),\n", "            nn.Dropout(0.2),\n", "            nn.Linear(128, num_classes),\n", "        )\n", "\n", "    def forward(self, x):\n", "        feat_short = self.conv_short(x)\n", "        feat_medium = self.conv_medium(x)\n", "        feat_long = self.conv_long(x)\n", "        merged = torch.cat([feat_short, feat_medium, feat_long], dim=1)\n", "        merged = self.merge(merged)\n", "\n", "        lstm_in = merged.transpose(1, 2)\n", "        lstm_out, _ = self.lstm(lstm_in)\n", "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n", "        temporal_features = attn_out.mean(dim=1)\n", "        cnn_features = self.global_pool(merged).squeeze(-1)\n", "        combined = torch.cat([temporal_features, cnn_features], dim=1)\n", "        return self.classifier(combined)\n"]}, {"cell_type": "code", "execution_count": 8, "id": "6d812a0e", "metadata": {"execution": {"iopub.execute_input": "2025-12-10T21:54:31.519995Z", "iopub.status.busy": "2025-12-10T21:54:31.519634Z", "iopub.status.idle": "2025-12-10T21:54:31.524400Z", "shell.execute_reply": "2025-12-10T21:54:31.523839Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================================================================\n", "LABEL ENCODING\n", "================================================================================\n", "Classes: {np.str_('high_stress'): 0, np.str_('low_stress'): 1, np.str_('moderate_stress'): 2, np.str_('no_stress'): 3}\n", "\n", "Encoded label distribution:\n", "  0: high_stress          \u2192   462 samples\n", "  1: low_stress           \u2192    91 samples\n", "  2: moderate_stress      \u2192   664 samples\n", "  3: no_stress            \u2192  5571 samples\n"]}], "source": ["# Training configuration\n", "EPOCHS = 40\n", "BATCH_SIZE = 32\n", "LR = 1e-3\n", "WEIGHT_DECAY = 1e-4\n", "MAX_GRAD_NORM = 1.0\n", "USE_MIXED_PRECISION = torch.cuda.is_available()\n", "\n", "le = LabelEncoder()\n", "encoded_labels = le.fit_transform(labels)\n", "num_classes = len(le.classes_)\n", "\n", "print(\"=\"*80)\n", "print(\"LABEL ENCODING\")\n", "print(\"=\"*80)\n", "print(\"Classes:\", dict(zip(le.classes_, range(num_classes))))\n", "print(f\"\n", "Encoded label distribution:\")\n", "for i, class_name in enumerate(le.classes_):\n", "    count = (encoded_labels == i).sum()\n", "    print(f\"  {i}: {class_name:20s} \u2192 {count:5d} samples\")\n"]}, {"cell_type": "code", "execution_count": 9, "id": "8869da7c", "metadata": {"execution": {"iopub.execute_input": "2025-12-10T21:54:31.527050Z", "iopub.status.busy": "2025-12-10T21:54:31.526744Z", "iopub.status.idle": "2025-12-10T21:55:06.772904Z", "shell.execute_reply": "2025-12-10T21:55:06.772238Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================================================================\n", "PHASE 1.3: ADVANCED CLASS BALANCING\n", "================================================================================\n", "\n", "Split strategy: GroupKFold fold 1/5\n", "  Train windows: 5426 from 29 subjects\n", "  Test windows:  1362 from 7 subjects\n", "\n", "Train subjects: S02, S04, S05, S06, S07, S09, S11, S12, S13, S15, S16, S17, S18, f01, f02, f03, f06, f07, f08, f09, f10, f11, f12, f13, f14, f15, f16, f17, f18\n", "Test subjects: S01, S03, S08, S10, S14, f04, f05\n", "\n", "Dataset split overview:\n", "  Train: (5426, 16, 240)\n", "  Test:  (1362, 16, 240)\n", "\n", "Train class distribution (BEFORE balancing):\n", "  high_stress         :   433 (  8.0%)\n", "  low_stress          :    83 (  1.5%)\n", "  moderate_stress     :   505 (  9.3%)\n", "  no_stress           :  4405 ( 81.2%)\n", "\n", "Test class distribution:\n", "  high_stress         :    29 (  2.1%)\n", "  low_stress          :     8 (  0.6%)\n", "  moderate_stress     :   159 ( 11.7%)\n", "  no_stress           :  1166 ( 85.6%)\n", "\n", "================================================================================\n", "APPLYING MULTI-STRATEGY BALANCING\n", "================================================================================\n", "\n", "Step 1: Temporal augmentation for minority classes...\n", "  high_stress: 433 samples \u2192 augmenting 2x\n", "  low_stress: 83 samples \u2192 augmenting 6x\n", "  moderate_stress: 505 samples \u2192 augmenting 1x\n", "\n", "After temporal augmentation:\n", "  Train: (7295, 16, 240)\n", "  high_stress         :  1299 ( 17.8%)\n", "  low_stress          :   581 (  8.0%)\n", "  moderate_stress     :  1010 ( 13.8%)\n", "  no_stress           :  4405 ( 60.4%)\n", "\n", "Step 2: Undersampling majority class (no_stress)...\n", "  Target sampling: {np.str_('high_stress'): np.int64(1299), np.str_('low_stress'): np.int64(581), np.str_('moderate_stress'): np.int64(1010), np.str_('no_stress'): 2598}\n", "\n", "After undersampling:\n", "  Train: (5488, 16, 240)\n", "  high_stress         :  1299 ( 23.7%)\n", "  low_stress          :   581 ( 10.6%)\n", "  moderate_stress     :  1010 ( 18.4%)\n", "  no_stress           :  2598 ( 47.3%)\n", "\n", "Step 3: SMOTE for remaining imbalance...\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/home/moh/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n", "  warnings.warn(\n", "/home/moh/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n", "  warnings.warn(\n", "/home/moh/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n", "  warnings.warn(\n", "/home/moh/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n", "  warnings.warn(\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "After SMOTE:\n", "  Train: (10392, 16, 240)\n", "  high_stress         :  2598 ( 25.0%)\n", "  low_stress          :  2598 ( 25.0%)\n", "  moderate_stress     :  2598 ( 25.0%)\n", "  no_stress           :  2598 ( 25.0%)\n", "\n", "================================================================================\n", "FINAL CLASS DISTRIBUTION\n", "================================================================================\n", "\n", "Train: (10392, 16, 240)\n", "  high_stress         :  2598 ( 25.0%)\n", "  low_stress          :  2598 ( 25.0%)\n", "  moderate_stress     :  2598 ( 25.0%)\n", "  no_stress           :  2598 ( 25.0%)\n", "\n", "Class weights for loss: {np.str_('high_stress'): np.float64(1.0), np.str_('low_stress'): np.float64(1.0), np.str_('moderate_stress'): np.float64(1.0), np.str_('no_stress'): np.float64(1.0)}\n", "\n", "================================================================================\n", "TRAINING: 20 epochs\n", "================================================================================\n", "Epoch 01 | Train Loss: 0.9673 | Val Loss: 0.7456 | Val Acc: 0.691 | Val F1 (macro): 0.317 | Val F1 (weighted): 0.755\n", "Epoch 02 | Train Loss: 0.6418 | Val Loss: 0.5358 | Val Acc: 0.773 | Val F1 (macro): 0.309 | Val F1 (weighted): 0.788\n", "Epoch 03 | Train Loss: 0.5818 | Val Loss: 0.5362 | Val Acc: 0.757 | Val F1 (macro): 0.350 | Val F1 (weighted): 0.802\n", "Epoch 04 | Train Loss: 0.5383 | Val Loss: 0.6120 | Val Acc: 0.760 | Val F1 (macro): 0.342 | Val F1 (weighted): 0.801\n", "Epoch 05 | Train Loss: 0.5171 | Val Loss: 0.5552 | Val Acc: 0.772 | Val F1 (macro): 0.309 | Val F1 (weighted): 0.797\n", "Epoch 06 | Train Loss: 0.4921 | Val Loss: 0.6226 | Val Acc: 0.754 | Val F1 (macro): 0.326 | Val F1 (weighted): 0.792\n", "Epoch 07 | Train Loss: 0.4185 | Val Loss: 0.5980 | Val Acc: 0.789 | Val F1 (macro): 0.358 | Val F1 (weighted): 0.823\n", "Epoch 08 | Train Loss: 0.3763 | Val Loss: 0.6676 | Val Acc: 0.761 | Val F1 (macro): 0.341 | Val F1 (weighted): 0.805\n", "Epoch 09 | Train Loss: 0.3706 | Val Loss: 0.7235 | Val Acc: 0.744 | Val F1 (macro): 0.329 | Val F1 (weighted): 0.790\n", "Epoch 10 | Train Loss: 0.3481 | Val Loss: 0.7277 | Val Acc: 0.737 | Val F1 (macro): 0.306 | Val F1 (weighted): 0.775\n", "Epoch 11 | Train Loss: 0.3189 | Val Loss: 0.6685 | Val Acc: 0.750 | Val F1 (macro): 0.320 | Val F1 (weighted): 0.790\n", "Epoch 12 | Train Loss: 0.2946 | Val Loss: 0.7360 | Val Acc: 0.755 | Val F1 (macro): 0.327 | Val F1 (weighted): 0.794\n", "Epoch 13 | Train Loss: 0.2853 | Val Loss: 0.7039 | Val Acc: 0.768 | Val F1 (macro): 0.342 | Val F1 (weighted): 0.810\n", "Epoch 14 | Train Loss: 0.2631 | Val Loss: 0.7870 | Val Acc: 0.740 | Val F1 (macro): 0.310 | Val F1 (weighted): 0.785\n", "Epoch 15 | Train Loss: 0.2519 | Val Loss: 0.8284 | Val Acc: 0.738 | Val F1 (macro): 0.309 | Val F1 (weighted): 0.784\n", "Epoch 16 | Train Loss: 0.2557 | Val Loss: 0.8737 | Val Acc: 0.739 | Val F1 (macro): 0.300 | Val F1 (weighted): 0.779\n", "Epoch 17 | Train Loss: 0.2389 | Val Loss: 0.8069 | Val Acc: 0.750 | Val F1 (macro): 0.310 | Val F1 (weighted): 0.788\n", "Epoch 18 | Train Loss: 0.2480 | Val Loss: 0.7858 | Val Acc: 0.756 | Val F1 (macro): 0.292 | Val F1 (weighted): 0.786\n", "Epoch 19 | Train Loss: 0.2465 | Val Loss: 0.8134 | Val Acc: 0.752 | Val F1 (macro): 0.312 | Val F1 (weighted): 0.792\n", "Epoch 20 | Train Loss: 0.2379 | Val Loss: 0.8493 | Val Acc: 0.741 | Val F1 (macro): 0.312 | Val F1 (weighted): 0.786\n", "\n", "================================================================================\n", "FINAL EVALUATION ON TEST SET\n", "================================================================================\n", "\n", "OVERALL METRICS:\n", "  Accuracy:         0.7408 (74.1%)\n", "  Macro F1:         0.3123 (31.2%)\n", "  Weighted F1:      0.7862 (78.6%)\n", "  Macro Precision:  0.3223\n", "  Macro Recall:     0.3474\n", "\n", "================================================================================\n", "PER-CLASS METRICS\n", "================================================================================\n", "\n", "                 precision    recall  f1-score   support\n", "\n", "    high_stress     0.0421    0.2759    0.0731        29\n", "     low_stress     0.0000    0.0000    0.0000         8\n", "moderate_stress     0.3052    0.2956    0.3003       159\n", "      no_stress     0.9418    0.8182    0.8756      1166\n", "\n", "       accuracy                         0.7408      1362\n", "      macro avg     0.3223    0.3474    0.3123      1362\n", "   weighted avg     0.8428    0.7408    0.7862      1362\n", "\n", "\n", "================================================================================\n", "CONFUSION MATRIX\n", "================================================================================\n", "\n", "                 high_stress  low_stress  moderate_stress  no_stress\n", "high_stress                8           0                3         18\n", "low_stress                 0           0                8          0\n", "moderate_stress           69           2               47         41\n", "no_stress                113           3               96        954\n", "\n", "================================================================================\n", "SUBJECT-LEVEL PERFORMANCE (TEST SET)\n", "================================================================================\n", "subject  samples accuracy macro_f1\n", "    S01      177    0.808    0.458\n", "    S03      137    0.832    0.360\n", "    S08      150    0.787    0.402\n", "    S10      157    0.796    0.418\n", "    S14      162    0.858    0.311\n", "    f04      249    0.739    0.425\n", "    f05      330    0.564    0.199\n", "\n", "================================================================================\n", "COMPARISON TO BASELINE\n", "================================================================================\n", "\n", "BASELINE (before Phase 1):\n", "  Accuracy:    75.9%\n", "  Macro F1:    36.0%\n", "\n", "PHASE 1 (subject-norm + enhanced channels + multi-strategy balancing):\n", "  Accuracy:    74.1%  (-1.8pp)\n", "  Macro F1:    31.2%  (-4.8pp)\n", "\n", "\u26a0 Improvement: -4.8pp. May need Phase 2 enhancements.\n", "\n", "================================================================================\n"]}], "source": ["from sklearn.model_selection import train_test_split, GroupKFold\n", "from sklearn.metrics import precision_score, recall_score, f1_score\n", "from scipy.interpolate import interp1d\n", "\n", "print(\"=\"*80)\n", "print(\"PHASE 2 PREPARATION: DATA BALANCING + TRAINING CONFIG\")\n", "print(\"=\"*80)\n", "\n", "def time_warp_augment(sequence, warp_factor):\n", "    \"\"\"Temporal stretch/compress via interpolation.\"\"\"\n", "    channels, length = sequence.shape\n", "    new_length = int(length * warp_factor)\n", "    warped = []\n", "    for ch in range(channels):\n", "        if new_length < 4:\n", "            warped.append(sequence[ch])\n", "            continue\n", "        f = interp1d(np.arange(length), sequence[ch], kind='cubic', fill_value='extrapolate')\n", "        new_indices = np.linspace(0, length - 1, new_length)\n", "        warped_ch = f(new_indices)\n", "        warped_ch_resampled = np.interp(np.arange(length), np.linspace(0, length - 1, new_length), warped_ch)\n", "        warped.append(warped_ch_resampled)\n", "    return np.array(warped, dtype=np.float32)\n", "\n", "\n", "def temporal_augmentation(X, y, augment_counts={'low_stress': 6, 'high_stress': 2, 'moderate_stress': 1}):\n", "    \"\"\"Augment minority classes with physiologically-plausible transforms.\"\"\"\n", "    X_aug = list(X)\n", "    y_aug = list(y)\n", "    for class_idx in range(num_classes):\n", "        class_name = le.classes_[class_idx]\n", "        if class_name not in augment_counts:\n", "            continue\n", "        class_mask = y == class_idx\n", "        class_samples = X[class_mask]\n", "        if not len(class_samples):\n", "            continue\n", "        aug_factor = augment_counts[class_name]\n", "        print(f\"  {class_name}: {class_mask.sum()} samples \u2192 augmenting {aug_factor}x\")\n", "        for sample in class_samples:\n", "            for _ in range(aug_factor):\n", "                warp_factor = np.random.uniform(0.90, 1.10)\n", "                aug_sample = time_warp_augment(sample, warp_factor)\n", "                noise_std = 0.05 * np.std(sample, axis=1, keepdims=True)\n", "                aug_sample = aug_sample + np.random.normal(0, noise_std, aug_sample.shape).astype(np.float32)\n", "                shift_range = int(0.15 * sample.shape[1])\n", "                if shift_range > 0:\n", "                    shift = np.random.randint(-shift_range, shift_range)\n", "                    aug_sample = np.roll(aug_sample, shift, axis=1)\n", "                X_aug.append(aug_sample)\n", "                y_aug.append(class_idx)\n", "    return np.array(X_aug, dtype=np.float32), np.array(y_aug)\n", "\n", "\n", "def rebalance_sequences(X, y, target_count=None):\n", "    \"\"\"Oversample minority classes to match the dominant class count.\"\"\"\n", "    class_counts = np.bincount(y, minlength=num_classes)\n", "    target = class_counts.max() if target_count is None else target_count\n", "    balanced_X = []\n", "    balanced_y = []\n", "    for class_idx in range(num_classes):\n", "        class_mask = y == class_idx\n", "        class_samples = X[class_mask]\n", "        if not len(class_samples):\n", "            continue\n", "        count = class_samples.shape[0]\n", "        if count >= target:\n", "            balanced_X.append(class_samples[:target])\n", "            balanced_y.append(np.full(target, class_idx))\n", "        else:\n", "            extra = target - count\n", "            extra_idx = np.random.choice(count, extra, replace=True)\n", "            augmented_samples = np.concatenate([class_samples, class_samples[extra_idx]], axis=0)\n", "            balanced_X.append(augmented_samples)\n", "            balanced_y.append(np.full(target, class_idx))\n", "    X_balanced = np.concatenate(balanced_X).astype(np.float32)\n", "    y_balanced = np.concatenate(balanced_y)\n", "    return X_balanced, y_balanced\n", "\n", "\n", "# Ensure sequences are float32\n", "sequences = sequences.astype(np.float32)\n", "\n", "# Subject-aware split for revalidation\n", "if GROUP_SPLIT:\n", "    if NUM_FOLDS < 2:\n", "        raise ValueError(\"NUM_FOLDS must be >= 2 for GroupKFold.\")\n", "    unique_subjects = np.unique(subjects)\n", "    if len(unique_subjects) < NUM_FOLDS:\n", "        raise ValueError(f\"Not enough subjects ({len(unique_subjects)}) for NUM_FOLDS={NUM_FOLDS}.\")\n", "    gkf = GroupKFold(n_splits=NUM_FOLDS)\n", "    splits = list(gkf.split(sequences, encoded_labels, groups=subjects))\n", "    if FOLD_INDEX >= len(splits):\n", "        raise ValueError(f\"FOLD_INDEX {FOLD_INDEX} out of range for {NUM_FOLDS} folds.\")\n", "    train_idx, test_idx = splits[FOLD_INDEX]\n", "    split_desc = f\"GroupKFold fold {FOLD_INDEX + 1}/{NUM_FOLDS}\"\n", "else:\n", "    train_idx, test_idx = train_test_split(\n", "        np.arange(len(sequences)),\n", "        test_size=0.2,\n", "        stratify=encoded_labels,\n", "        random_state=SEED,\n", "    )\n", "    split_desc = \"Stratified random 80/20 split\"\n", "\n", "X_train, X_test = sequences[train_idx], sequences[test_idx]\n", "y_train, y_test = encoded_labels[train_idx], encoded_labels[test_idx]\n", "train_subjects = subjects[train_idx]\n", "test_subjects = subjects[test_idx]\n", "held_out_subjects = test_subjects.copy()\n", "\n", "print(f\"\n", "Split strategy: {split_desc}\")\n", "print(f\"  Train windows: {X_train.shape[0]} from {len(np.unique(train_subjects))} subjects\")\n", "print(f\"  Test windows:  {X_test.shape[0]} from {len(np.unique(test_subjects))} subjects\")\n", "print(\"\n", "Train subjects:\", ', '.join(sorted(np.unique(train_subjects))))\n", "print(\"Test subjects:\", ', '.join(sorted(np.unique(test_subjects))))\n", "\n", "print(f\"\n", "Dataset split overview:\")\n", "print(f\"  Train: {X_train.shape}\")\n", "print(f\"  Test:  {X_test.shape}\")\n", "\n", "print(f\"\n", "Train class distribution (BEFORE balancing):\")\n", "for i, class_name in enumerate(le.classes_):\n", "    count = (y_train == i).sum()\n", "    pct = 100 * count / len(y_train)\n", "    print(f\"  {class_name:20s}: {count:5d} ({pct:5.1f}%)\")\n", "\n", "print(f\"\n", "Test class distribution:\")\n", "for i, class_name in enumerate(le.classes_):\n", "    count = (y_test == i).sum()\n", "    pct = 100 * count / len(y_test)\n", "    print(f\"  {class_name:20s}: {count:5d} ({pct:5.1f}%)\")\n", "\n", "if APPLY_SMOTE:\n", "    print(\"\n", "\" + \"=\"*80)\n", "    print(\"TEMPORAL AUGMENTATION + RESAMPLING\")\n", "    print(\"=\"*80)\n", "    print(\"\n", "Step 1: Temporal augmentation for minority classes...\")\n", "    X_train, y_train = temporal_augmentation(X_train, y_train)\n", "    print(f\"  After augmentation: {X_train.shape}\")\n", "    print(\"\n", "Step 2: Oversampling minorities to match majority...\")\n", "    X_train, y_train = rebalance_sequences(X_train, y_train)\n", "\n", "print(\"\n", "\" + \"=\"*80)\n", "print(\"FINAL CLASS DISTRIBUTION\")\n", "print(\"=\"*80)\n", "print(f\"\n", "Train: {X_train.shape}\")\n", "for i, class_name in enumerate(le.classes_):\n", "    count = (y_train == i).sum()\n", "    pct = 100 * count / len(y_train)\n", "    print(f\"  {class_name:20s}: {count:5d} ({pct:5.1f}%)\")\n", "\n", "# Create datasets\n", "X_train = X_train.astype(np.float32)\n", "X_test = X_test.astype(np.float32)\n", "train_dataset = SequenceDataset(X_train, y_train)\n", "test_dataset = SequenceDataset(X_test, y_test)\n", "\n", "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n", "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n", "\n", "class_counts = np.bincount(y_train, minlength=num_classes).clip(min=1)\n", "class_weights = len(y_train) / (num_classes * class_counts)\n", "alpha_tensor = torch.tensor(class_weights, dtype=torch.float32, device=device)\n", "\n", "print(f\"\n", "Class weights / alpha for focal loss: {dict(zip(le.classes_, class_weights))}\")\n", "\n", "\n", "class FocalLoss(nn.Module):\n", "    def __init__(self, alpha=None, gamma=2.0):\n", "        super().__init__()\n", "        self.alpha = alpha\n", "        self.gamma = gamma\n", "\n", "    def forward(self, logits, targets):\n", "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n", "        pt = torch.exp(-ce_loss)\n", "        if self.alpha is not None:\n", "            at = self.alpha[targets]\n", "            loss = at * (1 - pt) ** self.gamma * ce_loss\n", "        else:\n", "            loss = (1 - pt) ** self.gamma * ce_loss\n", "        return loss.mean()\n", "\n", "\n", "# Initialize model + optimizer/scheduler\n", "num_channels = sequences.shape[1]\n", "model = MultiScaleLSTMResNet(input_channels=num_channels, num_classes=num_classes).to(device)\n", "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, betas=(0.9, 0.999))\n", "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n", "criterion = FocalLoss(alpha=alpha_tensor, gamma=2.0)\n", "scaler = torch.cuda.amp.GradScaler(enabled=USE_MIXED_PRECISION)\n", "\n", "print(\"\n", "\" + \"=\"*80)\n", "print(f\"TRAINING: {EPOCHS} epochs (mixed precision: {USE_MIXED_PRECISION})\")\n", "print(\"=\"*80)\n", "\n", "best_val_f1 = 0.0\n", "best_model_state = None\n", "global_step = 0\n", "\n", "for epoch in range(1, EPOCHS + 1):\n", "    model.train()\n", "    train_loss = 0.0\n", "    for xb, yb in train_loader:\n", "        xb, yb = xb.to(device), yb.to(device)\n", "        optimizer.zero_grad(set_to_none=True)\n", "        with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION):\n", "            logits = model(xb)\n", "            loss = criterion(logits, yb)\n", "        scaler.scale(loss).backward()\n", "        scaler.unscale_(optimizer)\n", "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n", "        scaler.step(optimizer)\n", "        scaler.update()\n", "        train_loss += loss.item() * xb.size(0)\n", "        global_step += 1\n", "        scheduler.step(global_step)\n", "    train_loss /= len(train_loader.dataset)\n", "\n", "    model.eval()\n", "    val_loss = 0.0\n", "    all_preds = []\n", "    all_targets = []\n", "    with torch.no_grad():\n", "        for xb, yb in test_loader:\n", "            xb, yb = xb.to(device), yb.to(device)\n", "            with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION):\n", "                logits = model(xb)\n", "                loss = criterion(logits, yb)\n", "            val_loss += loss.item() * xb.size(0)\n", "            preds = torch.argmax(logits, dim=1)\n", "            all_preds.append(preds.cpu().numpy())\n", "            all_targets.append(yb.cpu().numpy())\n", "    val_loss /= len(test_loader.dataset)\n", "    all_preds = np.concatenate(all_preds)\n", "    all_targets = np.concatenate(all_targets)\n", "    val_acc = accuracy_score(all_targets, all_preds)\n", "    val_f1_macro = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n", "    val_f1_weighted = f1_score(all_targets, all_preds, average='weighted', zero_division=0)\n", "\n", "    if val_f1_macro > best_val_f1:\n", "        best_val_f1 = val_f1_macro\n", "        best_model_state = model.state_dict().copy()\n", "\n", "    print(\n", "        f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n", "        f\"Val Acc: {val_acc:.3f} | Val F1 (macro): {val_f1_macro:.3f} | Val F1 (weighted): {val_f1_weighted:.3f}\"\n", "    )\n", "\n", "# Load best model\n", "if best_model_state is not None:\n", "    model.load_state_dict(best_model_state)\n", "\n", "print(\"\n", "\" + \"=\"*80)\n", "print(\"FINAL EVALUATION ON TEST SET\")\n", "print(\"=\"*80)\n", "\n", "model.eval()\n", "all_preds = []\n", "all_targets = []\n", "with torch.no_grad():\n", "    for xb, yb in test_loader:\n", "        xb, yb = xb.to(device), yb.to(device)\n", "        logits = model(xb)\n", "        preds = torch.argmax(logits, dim=1)\n", "        all_preds.append(preds.cpu().numpy())\n", "        all_targets.append(yb.cpu().numpy())\n", "\n", "all_preds = np.concatenate(all_preds)\n", "all_targets = np.concatenate(all_targets)\n", "\n", "test_acc = accuracy_score(all_targets, all_preds)\n", "test_f1_macro = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n", "test_f1_weighted = f1_score(all_targets, all_preds, average='weighted', zero_division=0)\n", "test_precision_macro = precision_score(all_targets, all_preds, average='macro', zero_division=0)\n", "test_recall_macro = recall_score(all_targets, all_preds, average='macro', zero_division=0)\n", "\n", "print(f\"\n", "OVERALL METRICS:\")\n", "print(f\"  Accuracy:         {test_acc:.4f} ({test_acc*100:.1f}%)\")\n", "print(f\"  Macro F1:         {test_f1_macro:.4f} ({test_f1_macro*100:.1f}%)\")\n", "print(f\"  Weighted F1:      {test_f1_weighted:.4f} ({test_f1_weighted*100:.1f}%)\")\n", "print(f\"  Macro Precision:  {test_precision_macro:.4f}\")\n", "print(f\"  Macro Recall:     {test_recall_macro:.4f}\")\n", "\n", "print(\"\n", "\" + \"=\"*80)\n", "print(\"PER-CLASS METRICS\")\n", "print(\"=\"*80)\n", "print(\"\n", "\" + classification_report(all_targets, all_preds, target_names=le.classes_, digits=4, zero_division=0))\n", "\n", "from sklearn.metrics import confusion_matrix\n", "cm = confusion_matrix(all_targets, all_preds)\n", "cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n", "\n", "print(\"\n", "\" + \"=\"*80)\n", "print(\"CONFUSION MATRIX\")\n", "print(\"=\"*80)\n", "print(\"\n", "\" + str(cm_df))\n", "\n", "print(\"\n", "\" + \"=\"*80)\n", "print(\"SUBJECT-LEVEL PERFORMANCE (TEST SET)\")\n", "print(\"=\"*80)\n", "subject_records = []\n", "for subj in sorted(np.unique(held_out_subjects)):\n", "    subj_mask = held_out_subjects == subj\n", "    subj_true = all_targets[subj_mask]\n", "    subj_pred = all_preds[subj_mask]\n", "    subject_records.append({\n", "        \"subject\": subj,\n", "        \"samples\": int(subj_mask.sum()),\n", "        \"accuracy\": accuracy_score(subj_true, subj_pred) if subj_mask.sum() else 0.0,\n", "        \"macro_f1\": f1_score(subj_true, subj_pred, average='macro', zero_division=0),\n", "    })\n", "if subject_records:\n", "    subject_df = pd.DataFrame(subject_records)\n", "    print(subject_df.to_string(index=False, formatters={\n", "        \"accuracy\": \"{:.3f}\".format,\n", "        \"macro_f1\": \"{:.3f}\".format,\n", "    }))\n", "else:\n", "    print(\"No held-out subjects to report (check split configuration).\")\n", "\n", "print(\"\n", "\" + \"=\"*80)\n", "print(\"COMPARISON TO BASELINE\")\n", "print(\"=\"*80)\n", "print(\"\n", "BASELINE (before Phase 1):\")\n", "print(\"  Accuracy:    75.9%\")\n", "print(\"  Macro F1:    36.0%\")\n", "print(f\"\n", "PHASE 2 (multi-scale CNN + focal loss + improved training):\")\n", "print(f\"  Accuracy:    {test_acc*100:.1f}%  ({(test_acc-0.759)*100:+.1f}pp)\")\n", "print(f\"  Macro F1:    {test_f1_macro*100:.1f}%  ({(test_f1_macro-0.360)*100:+.1f}pp)\")\n", "\n", "improvement = (test_f1_macro - 0.360) * 100\n", "if improvement >= 8:\n", "    print(f\"\n", "\u2713 TARGET ACHIEVED! Macro F1 improved by {improvement:+.1f}pp (target: +8-12pp)\")\n", "elif improvement >= 5:\n", "    print(f\"\n", "\u2713 Good progress! Macro F1 improved by {improvement:+.1f}pp\")\n", "else:\n", "    print(f\"\n", "\u26a0 Improvement: {improvement:+.1f}pp. Continue with next phases if needed.\")\n", "\n", "print(\"\n", "\" + \"=\"*80)\n"]}], "metadata": {"kernelspec": {"display_name": "tf-gpu", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.9"}, "widgets": {"application/vnd.jupyter.widget-state+json": {"state": {"0a06208ad69c4d4cb51bc8eebda276aa": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1ba0702def68443a9a49a025c657c0d8": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_5a3694cf2e9445f1bf5a52bda7899e02", "IPY_MODEL_71d57578c1c647d29d1b8071b240a4d6", "IPY_MODEL_65a6f23625d04e6d80b824cebd1958ae"], "layout": "IPY_MODEL_f531ca6957d64026a8a94014c391c9a1", "tabbable": null, "tooltip": null}}, "3e57612d337444b4bdc18331dce1e1b4": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "4026a25d59cf4b31957fd9ce50ed8dab": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4d6d675daf2d444c83479d916217a54b": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_4026a25d59cf4b31957fd9ce50ed8dab", "max": 32, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_6dba705ea0664383be7e97b158b28635", "tabbable": null, "tooltip": null, "value": 32}}, "501340d6ffe34b8ea24bdfce1789db50": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "51ce5ef228c348c0971f89b65d476042": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "56c5cd6f12dd4d9c91b62ba94ae44692": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5a3694cf2e9445f1bf5a52bda7899e02": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_694899dc97064979ba116bb1fee488d3", "placeholder": "\u200b", "style": "IPY_MODEL_6fe3dd568d584fae87bd671de1fac4cd", "tabbable": null, "tooltip": null, "value": "AEROBIC:\u2007100%"}}, "5ccd35c4f50a46d4bc4ad88c507a1f6a": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "65a6f23625d04e6d80b824cebd1958ae": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_bd98d548ec72487db390252d7e8094f0", "placeholder": "\u200b", "style": "IPY_MODEL_51ce5ef228c348c0971f89b65d476042", "tabbable": null, "tooltip": null, "value": "\u200731/31\u2007[00:05&lt;00:00,\u2007\u20075.00it/s]"}}, "694899dc97064979ba116bb1fee488d3": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6d50418385a041b9af98b7cfeed1e33a": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_d6743247a80d4d56a9e7cd3489448f06", "IPY_MODEL_e15d66cb46264f7daa65c0fd68ea8e3f", "IPY_MODEL_c143b5c5b522418f8fac25c26ffff8db"], "layout": "IPY_MODEL_a7cc8694aba2495e858533109de756c7", "tabbable": null, "tooltip": null}}, "6dba705ea0664383be7e97b158b28635": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "6fe3dd568d584fae87bd671de1fac4cd": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "715a8526c838455e87345760f7c28ca2": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "71d57578c1c647d29d1b8071b240a4d6": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_b9c9213c10104315ba797d6be070cf5a", "max": 31, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_a5c4d5d14e3b446492e220fa0566f168", "tabbable": null, "tooltip": null, "value": 31}}, "8c74fef78b3c492ab703d122f0bd14ae": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_cb64fdd6be1c449b8d3d7c41ab6ee8b2", "IPY_MODEL_4d6d675daf2d444c83479d916217a54b", "IPY_MODEL_d492fb4d3ae34c2591209bd8755e20f7"], "layout": "IPY_MODEL_f737e8174d5f4a7ea76bdc16c1efefad", "tabbable": null, "tooltip": null}}, "8e14ab79b2d747bba8b988b989b7c449": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a5c4d5d14e3b446492e220fa0566f168": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "a7cc8694aba2495e858533109de756c7": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b9c9213c10104315ba797d6be070cf5a": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "bc4d6bece2aa4195a037c9446aec4e25": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "bd98d548ec72487db390252d7e8094f0": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c143b5c5b522418f8fac25c26ffff8db": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_501340d6ffe34b8ea24bdfce1789db50", "placeholder": "\u200b", "style": "IPY_MODEL_3e57612d337444b4bdc18331dce1e1b4", "tabbable": null, "tooltip": null, "value": "\u200737/37\u2007[00:07&lt;00:00,\u2007\u20073.77it/s]"}}, "cb64fdd6be1c449b8d3d7c41ab6ee8b2": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_56c5cd6f12dd4d9c91b62ba94ae44692", "placeholder": "\u200b", "style": "IPY_MODEL_bc4d6bece2aa4195a037c9446aec4e25", "tabbable": null, "tooltip": null, "value": "ANAEROBIC:\u2007100%"}}, "d0d9d02129c14bf0acb25f5484fbe88a": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d492fb4d3ae34c2591209bd8755e20f7": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_0a06208ad69c4d4cb51bc8eebda276aa", "placeholder": "\u200b", "style": "IPY_MODEL_5ccd35c4f50a46d4bc4ad88c507a1f6a", "tabbable": null, "tooltip": null, "value": "\u200732/32\u2007[00:04&lt;00:00,\u2007\u20074.78it/s]"}}, "d6743247a80d4d56a9e7cd3489448f06": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_d0d9d02129c14bf0acb25f5484fbe88a", "placeholder": "\u200b", "style": "IPY_MODEL_fd1013cb952a46e29bb979433a9a8759", "tabbable": null, "tooltip": null, "value": "STRESS:\u2007100%"}}, "e15d66cb46264f7daa65c0fd68ea8e3f": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_8e14ab79b2d747bba8b988b989b7c449", "max": 37, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_715a8526c838455e87345760f7c28ca2", "tabbable": null, "tooltip": null, "value": 37}}, "f531ca6957d64026a8a94014c391c9a1": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f737e8174d5f4a7ea76bdc16c1efefad": {"model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "fd1013cb952a46e29bb979433a9a8759": {"model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "model_name": "HTMLStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}}, "version_major": 2, "version_minor": 0}}}, "nbformat": 4, "nbformat_minor": 5}